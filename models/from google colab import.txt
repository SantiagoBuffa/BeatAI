from google.colab import userdata
import os, json

kaggle_username = userdata.get("kaggle_username")
kaggle_key = userdata.get("kaggle_key")

os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)
with open(os.path.expanduser("~/.kaggle/kaggle.json"), "w") as f:
    json.dump({"username": kaggle_username, "key": kaggle_key}, f)

os.chmod(os.path.expanduser("~/.kaggle/kaggle.json"), 0o600)

!pip install kaggle --quiet

!kaggle datasets download -d evilspirit05/ecg-analysis -p ./data --unzip



-------------

import matplotlib.pyplot as plt
import tensorflow as tf
import os
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

def preprocess_dataset(dataset_path):
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=5,
        width_shift_range=0.05,
        height_shift_range=0.05,
        zoom_range=0.05,
        shear_range=0.05,
        validation_split=0.15
    )

    img_height, img_width = 256, 192
    batch_size = 16

    train_generator = train_datagen.flow_from_directory(
        os.path.join(dataset_path, 'train'),
        target_size=(img_height, img_width),
        color_mode='grayscale',
        batch_size=batch_size,
        class_mode='categorical',
        subset='training',
        shuffle=True
    )

    val_generator = train_datagen.flow_from_directory(
        os.path.join(dataset_path, 'train'),
        target_size=(img_height, img_width),
        color_mode='grayscale',
        batch_size=batch_size,
        class_mode='categorical',
        subset='validation',
        shuffle=True
    )

    # Generador de test (sin augmentation)
    test_datagen = ImageDataGenerator(rescale=1./255)
    test_generator = test_datagen.flow_from_directory(
        os.path.join(dataset_path, 'test'),
        target_size=(img_height, img_width),
        color_mode='grayscale',
        batch_size=batch_size,
        class_mode='categorical',
        shuffle=False
    )

    return train_generator, val_generator, test_generator



---------------




from tensorflow.keras import layers
import tensorflow as tf

class AttentionLayer(layers.Layer):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        # Crear la capa solo una vez
        self.conv = layers.Conv2D(1, (7,7), padding='same', activation='sigmoid')

    def call(self, inputs):
        avg_pool = tf.reduce_mean(inputs, axis=-1, keepdims=True)
        max_pool = tf.reduce_max(inputs, axis=-1, keepdims=True)
        concat = tf.concat([avg_pool, max_pool], axis=-1)
        spatial_attention = self.conv(concat)  # <--- NO crear aquí la capa
        return inputs * spatial_attention








---------


def build_attention_model(img_height=256, img_width=192):
    inputs = layers.Input(shape=(img_height, img_width, 1))
    
    x = layers.Conv2D(32, (3,3), activation='relu', padding='same', name='conv1')(inputs)
    x = layers.MaxPooling2D(2,2)(x)
    
    x = layers.Conv2D(64, (3,3), activation='relu', padding='same', name='conv2')(x)
    x = AttentionLayer(name='attn1')(x)
    x = layers.MaxPooling2D(2,2)(x)
    
    x = layers.Conv2D(128, (3,3), activation='relu', padding='same', name='conv3')(x)
    x = AttentionLayer(name='attn2')(x)
    x = layers.MaxPooling2D(2,2)(x)
    
    x = layers.Flatten()(x)
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dropout(0.5)(x)
    outputs = layers.Dense(4, activation='softmax')(x)
    
    model = tf.keras.models.Model(inputs, outputs)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model





--------------

import cv2
def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    grad_model = tf.keras.models.Model(
        [model.inputs],
        [model.get_layer(last_conv_layer_name).output, model.output]
    )
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]
    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap + 1e-8)
    return heatmap.numpy()

def display_gradcam(img, heatmap, alpha=0.4):
    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    plt.imshow(img, cmap='gray')
    plt.imshow(heatmap_resized, cmap='jet', alpha=alpha)
    plt.axis('off')
    plt.show()
    
    
-------------

def visualize_attention(model, img_path, last_conv_layer='conv3'):
    """
    Genera y muestra Grad-CAM de una imagen de prueba usando el modelo dado.
    
    Args:
        model: Modelo Keras ya entrenado.
        img_path: Ruta a la imagen de prueba.
        last_conv_layer: Nombre de la última capa conv para Grad-CAM.
    """
    import cv2
    import numpy as np
    import matplotlib.pyplot as plt

    # Cargar imagen
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        raise FileNotFoundError(f"No se pudo cargar la imagen: {img_path}")
    
    # Redimensionar
    img = cv2.resize(img, (192, 256))
    img_array = img.astype('float32') / 255.0
    img_array = np.expand_dims(img_array, axis=(0, -1))  # (1, 256, 192, 1)

    # Generar heatmap Grad-CAM
    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer)

    # Visualizar superpuesto
    plt.imshow(img, cmap='gray')
    plt.imshow(cv2.resize(heatmap, (192, 256)), cmap='jet', alpha=0.4)
    plt.axis('off')
    plt.show()
    
    
    
----------------------



def show_graphs(history):
    plt.figure(figsize=(10,4))
    plt.subplot(1,2,1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1,2,2)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.show()

dataset_path = "./data/ECG_DATA/"

train_gen, val_gen, test_gen = preprocess_dataset(dataset_path)

model = build_attention_model()
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=2
)

show_graphs(history)
img_test_path = "data/ECG_DATA/test/ECG Images of Myocardial Infarction Patients (240x12=2880)/MI(100).jpg"
visualize_attention(model, img_test_path, last_conv_layer='conv3')


----------
model.save("models/ecg_attention_model.h5")

!git add ecg_attention_model.h5
!git commit -m "Guardar modelo entrenado"
!git push origin main


-----------

from tensorflow.keras.callbacks import ModelCheckpoint

model = build_attention_model()

checkpoint = ModelCheckpoint(
    "BeatAI/ecg_attention_model.h5",  # ruta dentro del repo
    monitor='val_accuracy',
    save_best_only=True,
    save_weights_only=False
)

history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10,
    callbacks=[checkpoint]
)

show_graphs(history)



-----------


test_loss, test_acc = model.evaluate(test_gen)
print(f"✅ Test Accuracy: {test_acc:.4f}")
